{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AUHack 2023 - Grundfos Hands-on ML Workshop - Building Type Classification\n",
    "The goal of this workshop is to introduce you to how and what real-world Data Science is.\n",
    "\n",
    "This workshop is based on an internal Data Hackthon, where the goal was to classify if a building is residential or non-residential. To do this we used iGRID heat meter data from a city in Denmark.\n",
    "\n",
    "As this is a hands-on workshop there are a number of exercises throughout the notebook. For each exercise I have provided a partial solution and a full solution. I strongly recommend that you to use `jupyterlab` because then the solutions are hidden by default.\n",
    "\n",
    "The workshop has 5 parts:\n",
    "* Loading Data\n",
    "* Data Engineering\n",
    "* Data Exploration\n",
    "* Feature Engineering\n",
    "* Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's import some of the common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "\n",
    "# ... and update a few of the default settings\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "p9.options.set_option('dpi', 300)\n",
    "p9.options.set_option('figure_size', (8, 4.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "We load the data from a Snowflake database using the `snowflake-connector-python` package and its `fetch_pandas_all()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "\n",
    "snowflake_user = ''\n",
    "snowflake_password = ''\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    account='da84422.west-europe.azure',\n",
    "    user=snowflake_user,\n",
    "    password=snowflake_password,\n",
    "    database='GF_PROD_DB',\n",
    "    schema='CURATED_HACKATHON',\n",
    "    )\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    cur.execute(\"select * from GF_PROD_DB.CURATED_HACKATHON.V_DATA;\")\n",
    "    heat_data=cur.fetch_pandas_all()\n",
    "    print('data:')\n",
    "    print(heat_data.head(3))\n",
    "    cur.execute(\"select * from GF_PROD_DB.CURATED_HACKATHON.V_METADATA;\")\n",
    "    metadata=cur.fetch_pandas_all()\n",
    "    print('\\nMetadata:')\n",
    "    print(metadata.head(3))\n",
    "finally:\n",
    "    cur.close()\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### EXERCISE 1\n",
    "* Is there any missing data? If yes, in which columns and how many datapoints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution for Exercise 1 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### EXERCISE 1 SOLUTION (PARTIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Consider using the Pandas DataFrames built-in functions `info()`.\n",
    "# Q: Which columns has missing data\n",
    "# Q2: What happens if you use the `isna()` on that column\n",
    "# Q3: Try applying `sum()` after `isna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### EXERCISE 1 SOLUTION (FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's use the `info()` function to get an overview.\n",
    "heat_data.info()\n",
    "metadata.info()\n",
    "\n",
    "# With this we notice that `LOCATION_ELEVATION` has a few missing values.\n",
    "print(f'\\nLOCATION_ELEVATION is missing for {metadata.LOCATION_ELEVATION.isna().sum()} out of {len(metadata)} buildings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### EXERCISE 1 END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's merge the heat meter data and metadata\n",
    "# NOTE: In the real world, I would also split data here, but for simplicity we do that later.\n",
    "data = metadata.merge(heat_data, how='left', on='METER_ID')\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Engineering\n",
    "The goal of this section is make the data understandable, usable, and trustworthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's select a meter_id to look at\n",
    "meter_id_to_plot = metadata.sample(n=1)['METER_ID'].iloc[0]\n",
    "print(f'We are investigating METER_ID = {meter_id_to_plot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's create a new dataframe only containing data from our selected METER_ID\n",
    "from siuba import _, select, mutate, group_by, ungroup, filter, summarize\n",
    "\n",
    "data_to_plot = (data >> filter(_.METER_ID == meter_id_to_plot)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's create a scatter plot of the ENERGY column\n",
    "from plotnine import ggplot, aes\n",
    "from plotnine import ggtitle, facet_wrap\n",
    "from plotnine import theme, element_text, xlim, scale_y_log10\n",
    "from plotnine import geom_point, geom_histogram, geom_density, geom_bar, geom_col\n",
    "\n",
    "(\n",
    "    ggplot(data_to_plot, aes(x='TIMESTAMP', y='ENERGY')) + \n",
    "    geom_point() +\n",
    "    theme(axis_text_x=element_text(rotation=90, hjust=0.5))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's have a look at all four values in heat_data at once.\n",
    "import patchworklib as pw\n",
    "\n",
    "p1 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='ENERGY')) + geom_point())\n",
    "p2 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='VOLUME')) + geom_point())\n",
    "p3 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='FORWARD_TEMPERATURE_CUMULATIVE')) + geom_point())\n",
    "p4 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='RETURN_TEMPERATURE_CUMULATIVE')) + geom_point())\n",
    "\n",
    "p = (p1 | p2) / (p3 | p4)\n",
    "\n",
    "p.savefig() # This is an artifact from Patchworklib and does not save anything, but its required to display the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# They are all cumulative, so let's convert time, energy, volume, and the temperatures to delta values.\n",
    "from siuba.dply.vector import lead, lag\n",
    "\n",
    "data = (\n",
    "    data >>\n",
    "    group_by('METER_ID') >>\n",
    "    mutate(\n",
    "        TIME_DELTA = _.TIMESTAMP - lag(_.TIMESTAMP, n=1, default=np.NaN),\n",
    "        ENERGY_DELTA = _.ENERGY - lag(_.ENERGY, n=1, default=None),\n",
    "        VOLUME_DELTA = _.VOLUME - lag(_.VOLUME, n=1, default=None),\n",
    "        FORWARD_TEMPERATURE_DELTA = _.FORWARD_TEMPERATURE_CUMULATIVE - lag(_.FORWARD_TEMPERATURE_CUMULATIVE, n=1, default=None),\n",
    "        RETURN_TEMPERATURE_DELTA = _.RETURN_TEMPERATURE_CUMULATIVE - lag(_.RETURN_TEMPERATURE_CUMULATIVE, n=1, default=None)\n",
    "    ) >>\n",
    "    ungroup()\n",
    ")\n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's have a look at the four newly created columns\n",
    "data_to_plot = (data >> filter(_.METER_ID == meter_id_to_plot)).reset_index()\n",
    "\n",
    "p1 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='ENERGY_DELTA')) + geom_point())\n",
    "p2 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='VOLUME_DELTA')) + geom_point())\n",
    "p3 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='FORWARD_TEMPERATURE_DELTA')) + geom_point())\n",
    "p4 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='RETURN_TEMPERATURE_DELTA')) + geom_point())\n",
    "\n",
    "p = (p1 | p2) / (p3 | p4)\n",
    "\n",
    "p.savefig() # This is an artifact from Patchworklib and does not save anything, but its required to display the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The measurements are *supposed* to be daily, but let's make a sanity check\n",
    "(\n",
    "    ggplot(data >> filter(-np.isnat(_.TIME_DELTA )), aes('TIME_DELTA')) + \n",
    "    geom_histogram(bins=40, fill='#e66066', color='black') +\n",
    "    scale_y_log10() +\n",
    "    ggtitle('Distribution of time between measurements (for all buildings)')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's make the daily estimates of each column.\n",
    "data = (\n",
    "    data >>\n",
    "    mutate(\n",
    "        ENERGY_DAILY = _.ENERGY_DELTA * (pd.Timedelta(hours=24) / _.TIME_DELTA),\n",
    "        VOLUME_DAILY = _.VOLUME_DELTA * (pd.Timedelta(hours=24) / _.TIME_DELTA),\n",
    "        FORWARD_TEMPERATURE_DAILY = _.FORWARD_TEMPERATURE_DELTA * (pd.Timedelta(hours=24) / _.TIME_DELTA),\n",
    "        RETURN_TEMPERATURE_DAILY = _.RETURN_TEMPERATURE_DELTA * (pd.Timedelta(hours=24) / _.TIME_DELTA),\n",
    "    )\n",
    ")\n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's compare the 'energy_delta' and the 'energy_daily'.\n",
    "data_to_plot = (data >> filter(_.METER_ID == meter_id_to_plot)).reset_index()\n",
    "\n",
    "p1 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='ENERGY_DELTA')) + geom_point() + ggtitle('This plot shows the non-normalised values'))\n",
    "p2 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='ENERGY_DAILY')) + geom_point() + ggtitle('This plot shows the normalised values with respect to the time gap'))\n",
    "p = (p1 | p2)\n",
    "p.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ... and similar comparison for 'forward_temperature'.\n",
    "p1 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='FORWARD_TEMPERATURE_DELTA')) + geom_point() + ggtitle('This plot shows the non-normalised values'))\n",
    "p2 = pw.load_ggplot(ggplot(data_to_plot, aes(x='TIMESTAMP', y='FORWARD_TEMPERATURE_DAILY')) + geom_point() + ggtitle('This plot shows the normalised values with respect to the time gap'))\n",
    "p = (p1 | p2)\n",
    "p.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's convert forward and return temperatures to Celcius.\n",
    "# NOTE: As `VOLUME_DAILY` might be 0 we replace np.inf with 0.\n",
    "data = (\n",
    "    data >>\n",
    "    mutate(\n",
    "        FORWARD_TEMPERATURE_CELCIUS_DAILY = _.FORWARD_TEMPERATURE_DAILY / _.VOLUME_DAILY,\n",
    "        RETURN_TEMPERATURE_CELCIUS_DAILY = _.RETURN_TEMPERATURE_DAILY / _.VOLUME_DAILY,\n",
    "    )\n",
    ").replace(np.inf, 0)\n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The temperatures should be between 0 and 100 degress Celcius. Let's make another sanity check\n",
    "(\n",
    "    ggplot(data) +\n",
    "    geom_histogram(aes('FORWARD_TEMPERATURE_CELCIUS_DAILY'), bins=40, fill='red', color='black', alpha=0.6) +\n",
    "    geom_histogram(aes('RETURN_TEMPERATURE_CELCIUS_DAILY'), bins=40, fill='blue', color='black', alpha=0.6) +\n",
    "    p9.scale_y_log10() +\n",
    "    ggtitle('Distribution of forward and return temperatures, respectively.')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### EXERCISE 2\n",
    "* Create a new column, `TEMPERATURE_DIFFERENCE_CELCIUS_DAILY`, which shows the difference between the Forward and the Return temperature.\n",
    "* Create a scatter plot showing `FORWARD_TEMPERATURE_CELCIUS_DAILY` in red and `RETURN_TEMPERATURE_CELCIUS_DAILY` in blue. **HINT**: Add two `geom_points()` to the same ggplot. See: https://plotnine.readthedocs.io/en/stable/generated/plotnine.geoms.geom_point.html\n",
    "* Create a scatter plot showing the new column `TEMPERATURE_DIFFERENCE_CELCIUS_DAILY`.\n",
    "* Combine the two plots using Patchworklib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution for Exercise 2 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### EXERCISE 2 SOLUTION (PARTIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's calculate the temperature difference.\n",
    "# Q: What should we write inside the mutate() function?\n",
    "data = (\n",
    "    data >>\n",
    "    mutate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's update data_to_plot with the newly create column.\n",
    "data_to_plot = (data >> filter(_.METER_ID == meter_id_to_plot)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's make the plot with forward and return temperature.\n",
    "# Q: What goes into the two geom_points?\n",
    "# HINT: Look at the plot above with two geom_histogram() functions\n",
    "(\n",
    "    ggplot(data_to_plot, aes(x='TIMESTAMP')) +\n",
    "    geom_point() +\n",
    "    geom_point() +\n",
    "    theme(axis_text_x = p9.element_text(rotation=90, hjust=0.35)) +\n",
    "    ggtitle('The forward (red) and return (blue) temperatures.')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's combine the two plots with Pathworklib.\n",
    "# Q: How do we combine p1 and p2?\n",
    "\n",
    "p1 = pw.load_ggplot(\n",
    "    ggplot(data_to_plot, aes(x='TIMESTAMP')) +\n",
    "    geom_point(aes(y='FORWARD_TEMPERATURE_CELCIUS_DAILY'), color='red') +\n",
    "    geom_point(aes(y='RETURN_TEMPERATURE_CELCIUS_DAILY'), color='blue') +\n",
    "    theme(axis_text_x = p9.element_text(rotation=90, hjust=0.35)) +\n",
    "    ggtitle('The forward (red) and return (blue) temperatures.')\n",
    ")\n",
    "p2 = pw.load_ggplot(\n",
    "    ggplot(data_to_plot, aes(x='TIMESTAMP',y='TEMPERATURE_DIFFERENCE_CELCIUS_DAILY')) +\n",
    "    geom_point() +\n",
    "    theme(axis_text_x = p9.element_text(rotation=90, hjust=0.35)) +\n",
    "    ggtitle('The difference between forward and return temperature.')\n",
    ")\n",
    "\n",
    "p = \n",
    "\n",
    "p.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### EXERCISE 2 SOLUTION (FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's calculate the temperature difference\n",
    "data = (\n",
    "    data >>\n",
    "    mutate(TEMPERATURE_DIFFERENCE_CELCIUS_DAILY = _.FORWARD_TEMPERATURE_CELCIUS_DAILY - _.RETURN_TEMPERATURE_CELCIUS_DAILY)\n",
    ")\n",
    "\n",
    "# Let`s plot the three temperatures\n",
    "data_to_plot = (data >> filter(_.METER_ID == meter_id_to_plot)).reset_index()\n",
    "\n",
    "p1 = pw.load_ggplot(\n",
    "    ggplot(data_to_plot, aes(x='TIMESTAMP')) +\n",
    "    geom_point(aes(y='FORWARD_TEMPERATURE_CELCIUS_DAILY'), color='red') +\n",
    "    geom_point(aes(y='RETURN_TEMPERATURE_CELCIUS_DAILY'), color='blue') +\n",
    "    theme(axis_text_x = p9.element_text(rotation=90, hjust=0.35)) +\n",
    "    ggtitle('The forward (red) and return (blue) temperatures.')\n",
    ")\n",
    "p2 = pw.load_ggplot(\n",
    "    ggplot(data_to_plot, aes(x='TIMESTAMP',y='TEMPERATURE_DIFFERENCE_CELCIUS_DAILY')) +\n",
    "    geom_point() +\n",
    "    theme(axis_text_x = p9.element_text(rotation=90, hjust=0.35)) +\n",
    "    ggtitle('The difference between forward and return temperature.')\n",
    ")\n",
    "p = (p1 | p2)\n",
    "p.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Exploration\n",
    "In this section we take a close look at the data and metadata, and try to get an intuitive understanding of the data and of what might impact our target; the type of building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, let's see the distrubution of our target; `BUILDING_TYPE`\n",
    "(\n",
    "    ggplot(metadata, aes('BUILDING_TYPE', fill='BUILDING_TYPE')) +\n",
    "    p9.geom_bar(color='black') +\n",
    "    ggtitle('The counts of residential and non-residentail meters included in the dataset')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's consider the metadata features and start with temperature difference.\n",
    "(\n",
    "    ggplot(data, aes('TEMPERATURE_DIFFERENCE_CELCIUS_DAILY', fill='BUILDING_TYPE')) +\n",
    "    geom_histogram(bins=30, color='black') +\n",
    "    xlim(-5, 60) +\n",
    "    ggtitle('The distribution of the temperature differences (for all meters)')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ... given the uneven distribution of residential and non-residential buildings, the above is hard to decipher. Let's split the plot using facet_wrap().\n",
    "(\n",
    "    ggplot(data, aes('TEMPERATURE_DIFFERENCE_CELCIUS_DAILY', fill='BUILDING_TYPE')) +\n",
    "    geom_histogram(bins=30, color='black') +\n",
    "    xlim(-5, 60) +\n",
    "    facet_wrap('~BUILDING_TYPE', scales='free_y') +\n",
    "    ggtitle('The distribution of the temperature differences (for all meters)')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ... and repeat this for ENERGY_DAILY.\n",
    "(\n",
    "    ggplot(data, aes('ENERGY_DAILY', fill='BUILDING_TYPE')) +\n",
    "    geom_histogram(bins=100, color='black') +\n",
    "    xlim(0, 1) +\n",
    "    facet_wrap('~BUILDING_TYPE', scales='free_y') +\n",
    "    ggtitle('The distribution of the daily energy consumption (for all meters)')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's look at a couple of the metadata variables.\n",
    "(\n",
    "    ggplot(metadata, aes('BUILT_UPON_AREA', fill='BUILDING_TYPE')) +\n",
    "    geom_histogram(bins=40, color='black') +\n",
    "    xlim(0, 2000) +\n",
    "    facet_wrap('~BUILDING_TYPE', scales='free_y') +\n",
    "    ggtitle('The distribution of the built upon area (for all meters)')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### EXERCISE 3\n",
    "* Make a histogram plot of the `LOCATION_ELEVATION` split by `BUILDING_TYPE`\n",
    "* What does this result tell us? (Can you use this to \"formulate\" a simple algorithm?)\n",
    "* I think this signal/result is surprising. Can you explain why it (probably) won't it generalize beyond this dataset to other cities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution for Exercise 3 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### EXERCISE 3 SOLUTION (PARTIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's look at the `LOCATION_ELEVATION`\n",
    "# Q: Which aesthetic should we look at and how do we want to fill (color) the bars in the histogram? I.e. fill out the aes() function below.\n",
    "\n",
    "(\n",
    "    ggplot(metadata, aes()) +\n",
    "    p9.geom_histogram(bins=55, color='black') +\n",
    "    p9.xlim(0, 55) +\n",
    "    facet_wrap('~BUILDING_TYPE', scales='free_y') +\n",
    "    ggtitle('The distribution of the elevation (for all meters)')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Q: To figure out what this plot tells, can you answer; Above which elevation are there no non-residential buildings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q: Do you think it is always the case, that non-residential buildings is close to sea level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### EXERCISE 3 SOLUTION (FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE 3 SOLUTION\n",
    "\n",
    "# Let's look at the `LOCATION_ELEVATION`\n",
    "(\n",
    "    ggplot(metadata, aes('LOCATION_ELEVATION', fill='BUILDING_TYPE')) +\n",
    "    p9.geom_histogram(bins=55, color='black') +\n",
    "    p9.xlim(0, 55) +\n",
    "    facet_wrap('~BUILDING_TYPE', scales='free_y') +\n",
    "    ggtitle('The distribution of the elevation (for all meters)')\n",
    ")\n",
    "# Answer: We can see that the non-residential building are closer to the sea level in this city. This is unlikely to generalize to other cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature engineering\n",
    "The goal of this section is extract features from the Time Series that can be used in our models.\n",
    "\n",
    "At the end of this section we will have a pruned dataset ready to use for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's calculate some features from the daily energy consumption using the `summarize()` function.\n",
    "features = (\n",
    "    data >>\n",
    "    group_by('METER_ID') >>\n",
    "    summarize(\n",
    "        ENERGY_DAILY_MEAN = _.ENERGY_DAILY.mean(),\n",
    "        ENERGY_DAILY_MEDIAN = _.ENERGY_DAILY.median(),\n",
    "        ENERGY_DAILY_CV = _.ENERGY_DAILY.std() / _.ENERGY_DAILY.mean(),\n",
    "        ENERGY_DAILY_AUTOCORR = _.ENERGY_DAILY.autocorr(),\n",
    "    )\n",
    ")\n",
    "\n",
    "features.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's add the BUILDING_TYPE and visualize.\n",
    "features = metadata.merge(features, how='left', on='METER_ID')\n",
    "features.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's plot the four features we just created\n",
    "# NOTE: We use geom_density here as there are (relatively) few datapoints/rows.\n",
    "p1 = pw.load_ggplot(\n",
    "    ggplot(features, aes('ENERGY_DAILY_MEAN', fill='BUILDING_TYPE')) +\n",
    "    p9.geom_density(alpha=0.5) +\n",
    "    p9.xlim(0, 1.5) +\n",
    "    ggtitle('The density of the Mean of the daily energy consumption')\n",
    ")\n",
    "\n",
    "p2 = pw.load_ggplot(\n",
    "    ggplot(features, aes('ENERGY_DAILY_MEDIAN', fill='BUILDING_TYPE')) +\n",
    "    p9.geom_density(alpha=0.5) +\n",
    "    p9.xlim(0, 1.5) +\n",
    "    ggtitle('The density of the Median of the daily energy consumption')\n",
    ")\n",
    "\n",
    "p3 = pw.load_ggplot(\n",
    "    ggplot(features, aes('ENERGY_DAILY_CV', fill='BUILDING_TYPE')) +\n",
    "    p9.geom_density(alpha=0.5) +\n",
    "    p9.xlim(0, 4) +\n",
    "    ggtitle('The density of the Coefficient of Variance of the daily energy consumption')\n",
    ")\n",
    "\n",
    "p4 = pw.load_ggplot(\n",
    "    ggplot(features, aes('ENERGY_DAILY_AUTOCORR', fill='BUILDING_TYPE')) +\n",
    "    p9.geom_density(alpha=0.5) +\n",
    "    p9.xlim(0, 1) +\n",
    "    ggtitle('The density of the Autocorrelation of the daily energy consumption')\n",
    ")\n",
    "\n",
    "p = (p1 | p2) / (p3 | p4)\n",
    "p.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#### EXERCISE 4:\n",
    "* Calculate `Mean` and `Coefficient of Variance` for daily Energy, Volume, Forward Temperature (celcius), Return Temperature (celcius), and Temperature Difference (celcius).\n",
    "**HINT**: overwrite the `features` DataFrame.\n",
    "* Calculate another feature!\n",
    "**HINT**: you can find inspiration for new features here: https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution for Exercise 4 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### EXERCISE 4 SOLUTION (PARTIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code calculate the `mean` and the `coefficient of variance` for energy. \n",
    "# Q: Can you do the same for volume? HINT: Add more lines inside the summarize() function.\n",
    "\n",
    "features = (\n",
    "    data >>\n",
    "    group_by('METER_ID') >>\n",
    "    summarize(\n",
    "        ENERGY_DAILY_MEAN = _.ENERGY_DAILY.mean(),\n",
    "        ENERGY_DAILY_CV = _.ENERGY_DAILY.std() / _.ENERGY_DAILY.mean(),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets try to calculate the 25% and 75% quantile for the energy.\n",
    "# HINT: Try to apply this function: https://pandas.pydata.org/docs/reference/api/pandas.Series.quantile.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### EXERCISE 4 SOLUTION (FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE 4 SOLUTION\n",
    "\n",
    "features = (\n",
    "    data >>\n",
    "    group_by('METER_ID') >>\n",
    "    summarize(\n",
    "        ENERGY_DAILY_MEAN = _.ENERGY_DAILY.mean(),\n",
    "        ENERGY_DAILY_MEDIAN = _.ENERGY_DAILY.median(),\n",
    "        ENERGY_DAILY_CV = _.ENERGY_DAILY.std() / _.ENERGY_DAILY.mean(),\n",
    "        ENERGY_DAILY_AUTOCORR = _.ENERGY_DAILY.autocorr(),\n",
    "        VOLUME_DAILY_MEAN = _.VOLUME_DAILY.mean(),\n",
    "        VOLUME_DAILY_CV = _.VOLUME_DAILY.std() / _.VOLUME_DAILY.mean(),\n",
    "        FORWARD_TEMPERATURE_CELCIUS_DAILY_MEAN = _.FORWARD_TEMPERATURE_CELCIUS_DAILY.mean(),\n",
    "        FORWARD_TEMPERATURE_CELCIUS_DAILY_CV = _.FORWARD_TEMPERATURE_CELCIUS_DAILY.std() / _.FORWARD_TEMPERATURE_CELCIUS_DAILY.mean(),\n",
    "        RETURN_TEMPERATURE_CELCIUS_DAILY_MEAN = _.RETURN_TEMPERATURE_CELCIUS_DAILY.mean(),\n",
    "        RETURN_TEMPERATURE_CELCIUS_DAILY_CV = _.RETURN_TEMPERATURE_CELCIUS_DAILY.std() / _.RETURN_TEMPERATURE_CELCIUS_DAILY.mean(),\n",
    "        TEMPERATURE_DIFFERENCE_CELCIUS_DAILY_MEAN = _.TEMPERATURE_DIFFERENCE_CELCIUS_DAILY.mean(),\n",
    "        TEMPERATURE_DIFFERENCE_CELCIUS_DAILY_CV = _.TEMPERATURE_DIFFERENCE_CELCIUS_DAILY.std() / _.TEMPERATURE_DIFFERENCE_CELCIUS_DAILY.mean(),\n",
    "        ENERGY_DAILY_Q25 = _.ENERGY_DAILY.quantile(q=0.25),\n",
    "        ENERGY_DAILY_Q75 = _.ENERGY_DAILY.quantile(q=0.75),\n",
    "        TEMPERATURE_DIFFERENCE_CELCIUS_DAILY_MIN = _.TEMPERATURE_DIFFERENCE_CELCIUS_DAILY.min(),\n",
    "        TEMPERATURE_DIFFERENCE_CELCIUS_DAILY_MAX = _.TEMPERATURE_DIFFERENCE_CELCIUS_DAILY.max(),\n",
    "    )\n",
    ")\n",
    "\n",
    "features.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### EXERCISE 4 END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's create our dataset for modelling. First lets remove unnecessary columns.\n",
    "data_final  = (\n",
    "    metadata >>\n",
    "    select(- _.contains('UNIT')) >>\n",
    "    select(- _.TIMESTAMP_TIMEZONE) >>\n",
    "    select(- _.METER_TYPE)\n",
    ").merge(features, how='left', on='METER_ID')\n",
    "\n",
    "data_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeling\n",
    "The goal of this section is train and test a simple model to predict the BUILDING_TYPE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data_final, test_size = 0.25, stratify=data_final['BUILDING_TYPE'])\n",
    "print(f'Number of train examples: {len(train)} out of {len(data_final)}.')\n",
    "print(f'Number of test examples: {len(test)} out of {len(data_final)}.')\n",
    "\n",
    "X_train = (\n",
    "    train >> \n",
    "    select(- _.BUILDING_TYPE) \n",
    ").fillna(0)\n",
    "\n",
    "y_train = (\n",
    "    train >> \n",
    "    select(_.BUILDING_TYPE)\n",
    ")\n",
    "\n",
    "X_test = (\n",
    "    test >> \n",
    "    select(- _.BUILDING_TYPE)\n",
    ").fillna(0)\n",
    "\n",
    "y_test = (\n",
    "    test >> \n",
    "    select(_.BUILDING_TYPE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets train a decision tree\n",
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "tree_accuracy = accuracy_score(y_test, y_pred)\n",
    "tree_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f'Our tree model has an accuracy of {tree_accuracy} and a balanced accuracy of {tree_balanced_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's have a look at the feature importance of our decision tree\n",
    "tree_feature_importance = clf.feature_importances_\n",
    "print(tree_feature_importance)\n",
    "\n",
    "importance_data = pd.DataFrame({'feature': X_train.columns, 'importance': tree_feature_importance})\n",
    "\n",
    "(\n",
    "    ggplot(importance_data, aes(x='feature', y='importance')) +\n",
    "    geom_col(fill='#e66066', color='black') +\n",
    "    theme(axis_text_x=element_text(rotation=90, hjust=0.5))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets train an SVM model (Support Vector Machine)\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_accuracy = accuracy_score(y_test, y_pred)\n",
    "svm_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f'Our tree model has an accuracy of {svm_accuracy} and a balanced accuracy of {svm_balanced_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets train an SGD model (Stochastic Gradiant Descent)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgd_accuracy = accuracy_score(y_test, y_pred)\n",
    "sgd_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f'Our tree model has an accuracy of {sgd_accuracy} and a balanced accuracy of {sgd_balanced_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#### EXERCISE 5\n",
    "* Select another scikit-learn classification model and train it.\n",
    "**HINT**: See: https://scikit-learn.org/stable/supervised_learning.html\n",
    "* Implement the `precision` metric from scikit-learn (assuming residential is the positive/default label).\n",
    "**HINT**: See: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution for Exercise 5 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### EXERCISE 5 SOLUTION (PRECISION-QUESTION, FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, pos_label='residential')\n",
    "precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
